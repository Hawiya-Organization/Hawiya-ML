{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa2cc857-4e50-4ec6-80e5-0f590f37b7e0",
   "metadata": {},
   "source": [
    "# preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4213789-a5f0-45d8-9b2d-ddfff188ad40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf25d26-4ce4-4114-9482-2fad03b685bf",
   "metadata": {},
   "source": [
    "# 1. Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe3cf3e7-526f-4457-957f-5d2c0380ffd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Arabic Poem Comprehensive Dataset (APCD).csv')\n",
    "df.drop(columns=['البيت' , 'العصر' , 'الديوان' , 'القافية' , 'الشاعر' , 'البحر'], inplace=True)\n",
    "df.dropna(subset=['الشطر الايمن', 'الشطر الايسر'], inplace=True)\n",
    "poems = df.rename(columns={\"الشطر الايمن\": \"prompt\", \"الشطر الايسر\": \"completion\"})[:50000].to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309ed626-48c7-445b-9c3d-4b73471ced73",
   "metadata": {},
   "source": [
    "# 2. Create Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "759b9af3-961a-4580-88fc-1fe41de52a90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PoemDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, poems, tokenizer, max_length):\n",
    "        self.poems = poems\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.poems)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        poem = self.poems[idx]\n",
    "        prompt = poem[\"prompt\"]\n",
    "        completion = poem[\"completion\"]\n",
    "\n",
    "        # Tokenize the prompt and completion\n",
    "        inputs = self.tokenizer.encode(prompt, add_special_tokens=True, max_length=self.max_length, truncation=True, padding='max_length', return_tensors=\"pt\")\n",
    "        labels = self.tokenizer.encode(completion, add_special_tokens=True, max_length=self.max_length, truncation=True, padding='max_length', return_tensors=\"pt\")\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": inputs.squeeze(0),  # Remove the batch dimension\n",
    "            \"labels\": labels.squeeze(0),      # Remove the batch dimension\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbd60a2a-6809-420d-84c1-f76af3f21bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class PoemDataset(torch.utils.data.Dataset):\n",
    "   # def __init__(self, poems):\n",
    "       # self.poems = poems\n",
    "\n",
    "  #  def __len__(self):\n",
    "     #   return len(self.poems)\n",
    "\n",
    "   # def __getitem__(self, idx):\n",
    "       #poem = self.poems[idx]\n",
    "        #prompt = poem[\"prompt\"]\n",
    "        #completion = poem[\"completion\"]\n",
    "        #encoded_data = tokenizer(prompt, completion, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "        #return encoded_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b897efd-5171-467b-9c0d-aefacdc9c498",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3. Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e0c4818-9d9b-48a5-942c-4def3e740c05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "414d74a3be7542b5aa8643574919b6e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/320M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs.huggingface.co/bakrianoo/t5-arabic-small/a4dfa25896e0801b897f27e5f4b683cbea05f267fb7d4f95522d04d255c1dd65?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27pytorch_model.bin%3B+filename%3D%22pytorch_model.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1712079249&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxMjA3OTI0OX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9iYWtyaWFub28vdDUtYXJhYmljLXNtYWxsL2E0ZGZhMjU4OTZlMDgwMWI4OTdmMjdlNWY0YjY4M2NiZWEwNWYyNjdmYjdkNGY5NTUyMmQwNGQyNTVjMWRkNjU%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=ciU6pgPXLpQby5xjQAqoN-v-x5yDsmv4wHVXTltvV6BysT6P-dnn5Wcm6L5QwbhynqLUrKWg08voBIDCCw9vT6YEIuh0te%7E0e8dvCOGn-xYBNjKcSsLoh6stwBwAgnry9di268VunAv1hOkEuo9CBYCPBr1LdFsvAKNrjQVtHruy-T97Eh8bUStHsUSxk8tkdqBEl8UC-ZrVh48IloU%7EmjNnEcNCDp%7E%7E%7EnUsjkjvkebcZaTS1xhQtqCSOSD8QHvfZgqY6EBa3uXQ36cqqKyGFhj7vX62b%7ErJn70CNsxQQ9phdURbDuJz9LIX1Z4NNTgvJ%7EPVrE1o-LfFkq-7KPjOIA__&Key-Pair-Id=KVTP0A1DKRTAX: HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d964a8216177428bb108ea313336bb2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/320M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97caa30d7cc6430989d2571c747a1c5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/173 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4e6e9f74b8a4198a8c427360e9b584f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/847k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42b5a82be6c04cc295320d21f558eee9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "model_name = \"bakrianoo/t5-arabic-small\" \n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d854b5c2-86ed-4328-abe1-cc85e432c9f2",
   "metadata": {},
   "source": [
    "# 4. Create Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b01eb32d-768d-440e-b5b5-7aab4bd2db88",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 64 \n",
    "\n",
    "# Create dataset and data loader\n",
    "dataset = PoemDataset(poems, tokenizer, max_length)\n",
    "data_loader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86fc22e0-f542-4f4a-94b8-fc78779b37d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f744b773910>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ef75bfd-3e41-48e0-a59c-be7f855e751c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Data Preparation Function \n",
    "#def prepare_data(data):\n",
    "    #encoded_data = tokenizer(data, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "    #return encoded_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19599d45-52af-4b88-b917-2273a14171a3",
   "metadata": {},
   "source": [
    "# 6. Optimizer and Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9706a227-98de-4437-bd99-46489d29f9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for data in data_loader:\n",
    "        inputs = data[\"input_ids\"]\n",
    "        labels = data[\"labels\"]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids=inputs, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98299586-3536-4854-a394-f0b09d24cded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.  Generation Function \n",
    "def generate_poem(prompt, max_length=50, temperature=1.0, num_beams=5):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    output = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        max_length=max_length,\n",
    "        temperature=temperature,\n",
    "        num_beams=num_beams,\n",
    "    )\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9982e462-8ab6-4ce8-84f9-39242350a2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<extra_id_0> على على رأسِه على رُؤوسِه\n"
     ]
    }
   ],
   "source": [
    "prompt = \"وردة حمراء تتفتح\"  \n",
    "generated_poem = generate_poem(prompt)\n",
    "print(generated_poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec51bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_soumia.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7f70db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_soumia_torch.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d175b1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
