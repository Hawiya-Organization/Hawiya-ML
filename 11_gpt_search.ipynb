{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fa484b6",
   "metadata": {},
   "source": [
    "## Import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dfeffde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-08 23:58:23.874323: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-08 23:58:24.512025: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-08 23:58:27.171987: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence embedding: [-1.7680897  -0.9779109   0.34898052 ... -0.3351004  -0.95397943\n",
      " -0.3652193 ]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer, set_seed\n",
    "import torch\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "set_seed(42)\n",
    "\n",
    "# Model and tokenizer\n",
    "model_name = \"elgeish/gpt2-medium-arabic-poetry\"\n",
    "model = AutoModel.from_pretrained(model_name).to(\"cuda\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Input prompt\n",
    "prompt = \"مثلجات سلطع برجر\"\n",
    "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "# Ensure the model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Get the model outputs\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids)\n",
    "\n",
    "# Extract hidden states from the last layer\n",
    "hidden_states = outputs.last_hidden_state\n",
    "\n",
    "# Calculate the sentence embedding as the mean of the token embeddings\n",
    "sentence_embedding = torch.mean(hidden_states, dim=1).squeeze()\n",
    "\n",
    "# Convert to numpy array (optional)\n",
    "sentence_embedding = sentence_embedding.cpu().numpy()\n",
    "\n",
    "print(\"Sentence embedding:\", sentence_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd09a43c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>البيت</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>خليلي لا تستعجلا أن تزودا    وأن تجمعا شملي وت...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>فما لبث يوما بسابق مغنم    ولا سرعتي يوما بساب...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>وإن تنظراني اليوم أقض لبانة    وتستوجبا منا عل...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>لعمرك ما نفس بجد رشيدة    تؤامرني سرا لأصرم مرثدا</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>وإن ظهرت منه قوارص جمة    وأفرع في لومي مرارا ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               البيت\n",
       "0  خليلي لا تستعجلا أن تزودا    وأن تجمعا شملي وت...\n",
       "1  فما لبث يوما بسابق مغنم    ولا سرعتي يوما بساب...\n",
       "2  وإن تنظراني اليوم أقض لبانة    وتستوجبا منا عل...\n",
       "3  لعمرك ما نفس بجد رشيدة    تؤامرني سرا لأصرم مرثدا\n",
       "4  وإن ظهرت منه قوارص جمة    وأفرع في لومي مرارا ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/apcd_clean.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d6f4f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (10000, 1024)\n",
      "[[-0.13975072 -0.54131925  0.89815    ...  1.9655814   1.9515972\n",
      "   0.01922477]\n",
      " [-0.09095679 -0.84680843 -0.64323944 ...  0.00599787  1.9318521\n",
      "   0.5713279 ]\n",
      " [-0.64327407 -1.5250567  -0.3005728  ...  1.0522782   1.817242\n",
      "   0.7140913 ]\n",
      " ...\n",
      " [-0.14110458 -1.3170115   0.7179195  ... -0.03673433 -0.19882926\n",
      "   0.24241851]\n",
      " [-0.02675416 -0.19866264  0.73517567 ...  0.26320434  1.4981219\n",
      "  -1.0008411 ]\n",
      " [ 0.23260784 -0.22998694  0.12302577 ...  0.85278064  1.686227\n",
      "  -0.3900748 ]]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "class PromptDataset(Dataset):\n",
    "    def __init__(self, prompts):\n",
    "        self.prompts = prompts\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.prompts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        prompt = self.prompts[idx]\n",
    "        input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").squeeze(0)\n",
    "        return input_ids\n",
    "\n",
    "# Create Dataset and DataLoader\n",
    "dataset = PromptDataset(df.sample(10_000, random_state=42)['البيت'].values)\n",
    "dataloader = DataLoader(dataset, batch_size=64, collate_fn=lambda x: torch.nn.utils.rnn.pad_sequence(x, batch_first=True))\n",
    "\n",
    "# Ensure the model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Function to extract embeddings\n",
    "def extract_embeddings(dataloader, model):\n",
    "    all_embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            batch = batch.to(\"cuda\")\n",
    "            outputs = model(batch)\n",
    "            hidden_states = outputs.last_hidden_state\n",
    "            # Calculate the sentence embedding as the mean of the token embeddings\n",
    "            batch_embeddings = torch.mean(hidden_states, dim=1)\n",
    "            all_embeddings.append(batch_embeddings)\n",
    "            \n",
    "            del batch\n",
    "            del outputs\n",
    "            del hidden_states\n",
    "            torch.cuda.empty_cache()\n",
    "    # Concatenate all embeddings\n",
    "    all_embeddings = torch.cat(all_embeddings, dim=0)\n",
    "    return all_embeddings\n",
    "\n",
    "# Extract embeddings\n",
    "embeddings = extract_embeddings(dataloader, model)\n",
    "\n",
    "# Convert to numpy array (optional)\n",
    "embeddings = embeddings.cpu().numpy()\n",
    "\n",
    "print(\"Embeddings shape:\", embeddings.shape)\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2fc943d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total vectors in the index: 10000\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "\n",
    "dimension = embeddings[0].shape[0]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(embeddings)\n",
    "print(f'Total vectors in the index: {index.ntotal}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50871948",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_indices = df.sample(10_000, random_state=42)['البيت'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27ca991d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    'الحماسة والفخر',\n",
    "    'روعة البحر',\n",
    "    'الأمل والتفاؤل',\n",
    "    'معاني الحياة والموت',\n",
    "    'وجدانية الحب العذري',\n",
    "    'التأمل في مصائر الإنسان',\n",
    "    'حياة العرب قبل الإسلام',\n",
    "    'العدمية والبحث عن الذات',\n",
    "    'الفضيلة والأخلاق',\n",
    "    'السلام والتسامح',\n",
    "    'العدالة والمساواة',\n",
    "    'كيف تخاف الفقر والله رازقا',\n",
    "    'التشرد والهجرة والبحث عن الوطن',\n",
    "    'عيناك نازلتاالقلوب',\n",
    "    ' كتب الدمع بخدي عهده',\n",
    "    'لا يحمل الحقد من تعلو به الرتب',\n",
    "    'أتعرف رسم الدار',\n",
    "    'الأصدقاء مثل النجوم',\n",
    "    ' أحلك الأوقات',\n",
    "    'شعر بدوي',\n",
    "    ' الثقة بالله',\n",
    "    ' ذكريات الطفولة',\n",
    "    'المرء يأمل أن يعيش',\n",
    "    'الوطن والانتماء',\n",
    "    ' الحرية والنضال',\n",
    "    'قم للمعلم وفه التبجيلا',\n",
    "    'وعذرتهم وعرفت ذنبي',\n",
    "    'إليك يا أمي',\n",
    "    'فأصبح بعد الحرب',\n",
    "    'إذا حكم القضاء',\n",
    "    'ليت الأحزان',\n",
    "    'فرحي مثل طائر',\n",
    "    'نار الغضب',\n",
    "    'صوت المطر ينعش روحي',\n",
    "    'تنير ليالي',\n",
    "    'إِن الثعالب بالضحى',\n",
    "    'صبور على مر الحوادث',\n",
    "    'البحث عن الحقيقة رحلة لا نهاية لها',\n",
    "    'مرآة الروح',\n",
    "    'كلما نسينا دروس الماضي',\n",
    "    'دع الأيام تفعل ما تشاء',\n",
    "    'وقفت على الديار',\n",
    "    'رمال الصحراء',\n",
    "    'شموخ',\n",
    "    'تفاؤل',\n",
    "    'نصر',\n",
    "    'حمامة',\n",
    "    'ساذج'\n",
    "]\n",
    "\n",
    "f = open(\"output_gpt2.txt\", 'w')\n",
    "\n",
    "for prompt in prompts:\n",
    "    f.write(prompt + \"\\n\")\n",
    "\n",
    "    set_seed(42)\n",
    "\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "\n",
    "    # Extract hidden states from the last layer\n",
    "    hidden_states = outputs.last_hidden_state\n",
    "\n",
    "    # Calculate the sentence embedding as the mean of the token embeddings\n",
    "    sentence_embedding = torch.mean(hidden_states, dim=1).squeeze()\n",
    "\n",
    "    # Convert to numpy array (optional)\n",
    "    query_vector = sentence_embedding.cpu().numpy().reshape(1, -1)\n",
    "    \n",
    "    distances, indices = index.search(query_vector, 50)\n",
    "    df_prompt_result = df.loc[original_indices[indices.flatten()]]\n",
    "    df_prompt_result['n'] = df_prompt_result['البيت'].apply(len)\n",
    "    df_prompt_result = df_prompt_result.loc[df_prompt_result['n'] > 10]\n",
    "    df_prompt_result.reset_index(inplace=True)\n",
    "    \n",
    "    f.write(df_prompt_result.at[0, 'البيت'] + \"\\n\")\n",
    "    f.write(df_prompt_result.at[1, 'البيت'] + \"\\n\")\n",
    "    f.write(df_prompt_result.at[2, 'البيت'] + \"\\n\")\n",
    "    \n",
    "    f.write(\"\\n\")\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f0e7620",
   "metadata": {},
   "outputs": [],
   "source": [
    "#faiss.write_index(index, 'vector_index.faiss')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
